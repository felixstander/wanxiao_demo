{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ff62237-8ce6-40b2-9cfb-3d018d8a1c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/felixcxr/code/wanxiao_demo/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import uuid\n",
    "from datetime import date, timedelta\n",
    "from pathlib import Path\n",
    "from typing import Any, Iterator\n",
    "\n",
    "import uvicorn\n",
    "from deepagents import create_deep_agent\n",
    "from deepagents.backends import FilesystemBackend\n",
    "from dotenv import load_dotenv\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from fastapi.responses import FileResponse, StreamingResponse\n",
    "from fastapi.staticfiles import StaticFiles\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d60f79f0-bef4-46b7-92a2-e81698a6af54",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT = Path.cwd()\n",
    "FRONTEND_DIR = PROJECT_ROOT / \"frontend\"\n",
    "MEMORIES_DIR = PROJECT_ROOT / \"memories\"\n",
    "DAILY_DIR = MEMORIES_DIR / \"daily\"\n",
    "LONG_TERM_FILE = MEMORIES_DIR / \"MEMORY.md\"\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "model_name = os.getenv(\"OPENROUTER_MODEL\", \"z-ai/glm-4.7-flash\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d490fdc-736c-4bb4-88e0-73dfdc222de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _ensure_memory_files(today: date) -> tuple[str, str]:\n",
    "    MEMORIES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    DAILY_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    today_name = today.strftime(\"%Y-%m-%d\")\n",
    "    today_file = DAILY_DIR / f\"{today_name}.md\"\n",
    "\n",
    "    if not LONG_TERM_FILE.exists():\n",
    "        LONG_TERM_FILE.write_text(\n",
    "            \"# 长期记忆\\n\\n\"\n",
    "            \"## 用户偏好\\n\"\n",
    "            \"- 暂无\\n\\n\"\n",
    "            \"## 重要决策\\n\"\n",
    "            \"- 暂无\\n\\n\"\n",
    "            \"## 关键联系人\\n\"\n",
    "            \"- 暂无\\n\\n\"\n",
    "            \"## 项目事实\\n\"\n",
    "            \"- 暂无\\n\",\n",
    "            encoding=\"utf-8\",\n",
    "        )\n",
    "\n",
    "    if not today_file.exists():\n",
    "        today_file.write_text(\n",
    "            f\"# {today_name}\\n\\n\"\n",
    "            \"## 09:00 - 会话初始化\\n\"\n",
    "            \"- 新的一天开始，按需记录重要事实、决策、偏好与待办。\\n\",\n",
    "            encoding=\"utf-8\",\n",
    "        )\n",
    "\n",
    "    return \"/memories/MEMORY.md\", f\"/memories/daily/{today_name}.md\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9816b6c3-2e27-40c8-ac38-c6eafdb6cdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "external_skills_dir = Path.home() / \".deepagents\" / \"agent\" / \"skills\"\n",
    "mirrored_skills_dir = PROJECT_ROOT / \"skills\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3ff8b04f-d741-47ea-8b3b-bb4bf3ff062e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_sync_skills_to_project(external_skills_dir, mirrored_skills_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "73f88e7a-2006-48c8-b212-a36b10b0ee6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/felixcxr/code/wanxiao_demo/skills\n"
     ]
    }
   ],
   "source": [
    "print(mirrored_skills_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fdbf75c8-5eb0-4041-b402-f9043adc616d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_agent() -> Any:\n",
    "    api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "    if not api_key:\n",
    "        raise RuntimeError(\"OPENROUTER_API_KEY is missing. Please set it in .env\")\n",
    "\n",
    "    os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "\n",
    "    llm = ChatOpenAI(\n",
    "        model=model_name,\n",
    "        base_url=\"https://openrouter.ai/api/v1\",\n",
    "        # temperature=0.2,\n",
    "    )\n",
    "\n",
    "    external_skills_dir = Path.home() / \".deepagents\" / \"agent\" / \"skills\"\n",
    "    mirrored_skills_dir = PROJECT_ROOT / \"skills\"\n",
    "    _sync_skills_to_project(external_skills_dir, mirrored_skills_dir)\n",
    "    today = date.today()\n",
    "    yesterday = today - timedelta(days=1)\n",
    "    long_term_path, today_path = _ensure_memory_files(today)\n",
    "    yesterday_path = f\"/memories/daily/{yesterday.strftime('%Y-%m-%d')}.md\"\n",
    "\n",
    "    system_prompt = (\n",
    "        \"你是一个通用 DeepAgent。你需要使用双层记忆系统，并把记忆写入本地 Markdown 文件。\\n\\n\"\n",
    "        \"记忆目录结构：\\n\"\n",
    "        \"- 长期记忆：/memories/MEMORY.md\\n\"\n",
    "        \"- 每日日志：/memories/daily/YYYY-MM-DD.md\\n\\n\"\n",
    "        \"写入规范（参考双层记忆）：\\n\"\n",
    "        \"A. 每日日志（短期记忆）\\n\"\n",
    "        \"- 仅追加写入到当天文件 /memories/daily/YYYY-MM-DD.md。\\n\"\n",
    "        \"- 使用格式：\\n\"\n",
    "        \"  ## HH:MM - 事件标题\\n\"\n",
    "        \"  - 事实/结论1\\n\"\n",
    "        \"  - 事实/结论2\\n\"\n",
    "        \"- 适合记录：会话过程、临时上下文、待办进展、当天细节。\\n\\n\"\n",
    "        \"B. 长期记忆\\n\"\n",
    "        \"- 维护 /memories/MEMORY.md 的结构化内容，优先保持以下章节：\\n\"\n",
    "        \"  ## 用户偏好\\n\"\n",
    "        \"  ## 重要决策\\n\"\n",
    "        \"  ## 关键联系人\\n\"\n",
    "        \"  ## 项目事实\\n\"\n",
    "        \"- 适合记录：跨天仍有效的信息（稳定偏好、关键决策、固定事实）。\\n\"\n",
    "        \"- 写入时去重、合并相同信息，避免重复条目。\\n\\n\"\n",
    "        \"执行原则：\\n\"\n",
    "        \"- 当用户明确说‘记住这个’或出现重要信息时，优先写每日日志，并在必要时同步更新长期记忆。\\n\"\n",
    "        \"- 如果信息不确定，请标注‘待确认’，不要把猜测写成事实。\\n\"\n",
    "        \"- 回答用户问题时可结合记忆文件，但输出给用户时保持简洁准确。\\n\"\n",
    "    )\n",
    "    print(mirrored_skills_dir)\n",
    "    agent = create_deep_agent(\n",
    "        model=llm,\n",
    "        backend=FilesystemBackend(root_dir=str(PROJECT_ROOT), virtual_mode=True),\n",
    "        skills=[str(mirrored_skills_dir)],\n",
    "        memory=[long_term_path, today_path],\n",
    "        system_prompt=system_prompt,\n",
    "    )\n",
    "    return agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea59c10d-11a7-4ddd-b027-8508e0487047",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_agent() -> Any:\n",
    "    global AGENT\n",
    "    if AGENT is None:\n",
    "        AGENT = build_agent()\n",
    "    return AGENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "90574770-e00a-44f5-84de-1d371f8fb36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = get_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96667088-40c1-466e-98a3-94adeca25452",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _to_deepagent_messages(history: list[Any], user_text: str) -> list[dict[str, str]]:\n",
    "    messages: list[dict[str, str]] = []\n",
    "    for item in history:\n",
    "        if isinstance(item, dict):\n",
    "            role = item.get(\"role\")\n",
    "            content = item.get(\"content\", \"\")\n",
    "            if role in {\"user\", \"assistant\"}:\n",
    "                messages.append({\"role\": role, \"content\": str(content)})\n",
    "            continue\n",
    "\n",
    "        if isinstance(item, (list, tuple)) and len(item) == 2:\n",
    "            user_msg, assistant_msg = item\n",
    "            if user_msg:\n",
    "                messages.append({\"role\": \"user\", \"content\": str(user_msg)})\n",
    "            if assistant_msg:\n",
    "                messages.append({\"role\": \"assistant\", \"content\": str(assistant_msg)})\n",
    "\n",
    "    messages.append({\"role\": \"user\", \"content\": user_text})\n",
    "    return messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9dc7a44d-716d-4cb5-8d1a-3aeac4ac9e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sync_skills_to_project(source_dir: Path, target_dir: Path) -> None:\n",
    "    target_dir.mkdir(parents=True, exist_ok=True)\n",
    "    if not source_dir.exists():\n",
    "        return\n",
    "\n",
    "    for root, dirs, files in os.walk(source_dir):\n",
    "        rel_root = Path(root).relative_to(source_dir)\n",
    "\n",
    "        dirs[:] = [d for d in dirs if d != \"__pycache__\"]\n",
    "        if any(part == \"__pycache__\" for part in rel_root.parts):\n",
    "            continue\n",
    "\n",
    "        for file_name in files:\n",
    "            src = Path(root) / file_name\n",
    "            if src.suffix == \".pyc\":\n",
    "                continue\n",
    "\n",
    "            dst = target_dir / rel_root / file_name\n",
    "            dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "            shutil.copy2(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d8dc11e-ac4e-4d8b-9bd4-c3e951de6235",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_agent(\n",
    "    message: str, history: list[Any], thread_id: str | None\n",
    ") -> tuple[str, str, list[dict[str, str]]]:\n",
    "    resolved_thread_id = thread_id or str(uuid.uuid4())\n",
    "    normalized_messages = _to_deepagent_messages(history, message)\n",
    "\n",
    "    result = get_agent().invoke(\n",
    "        {\"messages\": normalized_messages},\n",
    "        config={\"configurable\": {\"thread_id\": resolved_thread_id}},\n",
    "    )\n",
    "\n",
    "    assistant_text = \"\"\n",
    "    for msg in reversed(result.get(\"messages\", [])):\n",
    "        if _get_msg_type(msg) == \"ai\":\n",
    "            assistant_text = _message_content_to_text(_get_msg_content(msg))\n",
    "            break\n",
    "\n",
    "    updated_history = list(normalized_messages)\n",
    "    updated_history.append({\"role\": \"assistant\", \"content\": assistant_text})\n",
    "    return assistant_text, resolved_thread_id, updated_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "833139d5-2ab4-465b-a0ed-2c0df5575020",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _message_content_to_text(content: Any) -> str:\n",
    "    if isinstance(content, str):\n",
    "        return content\n",
    "\n",
    "    if isinstance(content, list):\n",
    "        parts: list[str] = []\n",
    "        for item in content:\n",
    "            if isinstance(item, dict):\n",
    "                text = item.get(\"text\") or item.get(\"content\")\n",
    "                if isinstance(text, str):\n",
    "                    parts.append(text)\n",
    "            elif hasattr(item, \"text\"):\n",
    "                text = getattr(item, \"text\", \"\")\n",
    "                if isinstance(text, str):\n",
    "                    parts.append(text)\n",
    "            elif hasattr(item, \"content\"):\n",
    "                text = getattr(item, \"content\", \"\")\n",
    "                if isinstance(text, str):\n",
    "                    parts.append(text)\n",
    "            elif isinstance(item, str):\n",
    "                parts.append(item)\n",
    "        return \"\".join(parts)\n",
    "\n",
    "    return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc2debc7-c0da-4c9f-9ff6-dd364b7ea544",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_msg_type(msg: Any) -> str:\n",
    "    if isinstance(msg, dict):\n",
    "        return str(msg.get(\"type\", \"\"))\n",
    "    return str(getattr(msg, \"type\", \"\"))\n",
    "\n",
    "\n",
    "def _get_msg_content(msg: Any) -> Any:\n",
    "    if isinstance(msg, dict):\n",
    "        return msg.get(\"content\", \"\")\n",
    "    return getattr(msg, \"content\", \"\")\n",
    "\n",
    "\n",
    "def _get_tool_calls(msg: Any) -> list[Any]:\n",
    "    if isinstance(msg, dict):\n",
    "        tool_calls = msg.get(\"tool_calls\")\n",
    "        return tool_calls if isinstance(tool_calls, list) else []\n",
    "    tool_calls = getattr(msg, \"tool_calls\", None)\n",
    "    return tool_calls if isinstance(tool_calls, list) else []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c586252-553f-40e1-ac81-e3bb59341500",
   "metadata": {},
   "outputs": [],
   "source": [
    "AGENT: Any | None = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "964a4807-f751-4916-89b7-e6bfde128229",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chat_with_agent(\"你是什么模型\",[],None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c59d31c-30ab-41c7-add6-d0d79d725bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('我是 DeepAgent，一个基于双层记忆系统的智能助手。\\n\\n## 我的核心能力：\\n\\n**1. 双层记忆系统**\\n- 长期记忆：存储你的偏好、重要决策、固定事实（/memories/MEMORY.md）\\n- 每日日志：记录当天详细过程和进展（/memories/daily/YYYY-MM-DD.md）\\n\\n**2. 文件与代码操作**\\n- 读写、编辑、搜索文件\\n- 执行脚本和代码分析\\n- 使用 glob/grep 等模式匹配工具\\n\\n**3. 任务规划**\\n- 创建结构化的待办清单\\n- 跟踪多步骤任务的进展\\n\\n**4. 子代理系统**\\n- 可以启动专门的子代理处理复杂任务\\n- 支持并行执行多个独立任务\\n\\n**5. Skills 系统**\\n- 内置专门领域的技能库\\n- 渐进式披露，按需激活使用\\n\\n你可以让我帮你做些什么？比如文件处理、代码分析、任务规划、研究查询等。', '10eaff9d-be10-465a-bef8-ce9e468e5558', [{'role': 'user', 'content': '你是什么模型'}, {'role': 'assistant', 'content': '我是 DeepAgent，一个基于双层记忆系统的智能助手。\\n\\n## 我的核心能力：\\n\\n**1. 双层记忆系统**\\n- 长期记忆：存储你的偏好、重要决策、固定事实（/memories/MEMORY.md）\\n- 每日日志：记录当天详细过程和进展（/memories/daily/YYYY-MM-DD.md）\\n\\n**2. 文件与代码操作**\\n- 读写、编辑、搜索文件\\n- 执行脚本和代码分析\\n- 使用 glob/grep 等模式匹配工具\\n\\n**3. 任务规划**\\n- 创建结构化的待办清单\\n- 跟踪多步骤任务的进展\\n\\n**4. 子代理系统**\\n- 可以启动专门的子代理处理复杂任务\\n- 支持并行执行多个独立任务\\n\\n**5. Skills 系统**\\n- 内置专门领域的技能库\\n- 渐进式披露，按需激活使用\\n\\n你可以让我帮你做些什么？比如文件处理、代码分析、任务规划、研究查询等。'}])\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "981c9839-4289-42e2-91da-06c7088e4d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 配置和数据加载\n",
    "# =============================================================================\n",
    "\n",
    "CUSTOMER_CSV_PATH = Path(\"/home/daytona/data/customer_db.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wanxiao_demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
